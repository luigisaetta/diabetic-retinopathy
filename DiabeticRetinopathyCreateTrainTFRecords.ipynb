{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy Image Preprocessing and tfrecords creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re, math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# check TF version (want: 2.3)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/ubuntu/kaggle/diabetic'\n",
    "\n",
    "FILE_LABELS = os.path.join(BASE_DIR, 'trainLabels.csv')\n",
    "TRAIN_IMAGES_DIR = os.path.join(BASE_DIR, 'train')\n",
    "\n",
    "TFREC_DIR = os.path.join(BASE_DIR, 'tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(FILE_LABELS)\n",
    "\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_labels.level.hist(bins = [0,1,2,3,4,5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level\n",
       "0    25810\n",
       "1     2443\n",
       "2     5292\n",
       "3      873\n",
       "4      708\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.groupby(['level']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codice preparazione file tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    \n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    \n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, crop=False, blur = False, sigmaX=10):\n",
    "    # CV2 per default tratta le immagini come BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if crop == True:\n",
    "        image = crop_image_from_gray(image)\n",
    "    \n",
    "    image = cv2.resize(image, (IMG_PIXEL, IMG_PIXEL), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    if blur == True:\n",
    "        image = cv2.addWeighted (image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions from TF2 docs\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(img, patient_id, side, label):\n",
    "  feature = {\n",
    "      'image': _bytes_feature(img),\n",
    "      'patient_id': _int64_feature(patient_id),\n",
    "      'side': _int64_feature(side),       # 0,1, left,right\n",
    "      'label': _int64_feature(label) # [0, 4]\n",
    "  }\n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing TFRecord 1 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  838.7  (sec)\n",
      "\n",
      "Writing TFRecord 2 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  820.9  (sec)\n",
      "\n",
      "Writing TFRecord 3 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  832.9  (sec)\n",
      "\n",
      "Writing TFRecord 4 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  850.5  (sec)\n",
      "\n",
      "Writing TFRecord 5 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  827.0  (sec)\n",
      "\n",
      "Writing TFRecord 6 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  845.6  (sec)\n",
      "\n",
      "Writing TFRecord 7 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  821.9  (sec)\n",
      "\n",
      "Writing TFRecord 8 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  836.2  (sec)\n",
      "\n",
      "Writing TFRecord 9 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  832.6  (sec)\n",
      "\n",
      "Writing TFRecord 10 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  825.3  (sec)\n",
      "\n",
      "Writing TFRecord 11 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  839.9  (sec)\n",
      "\n",
      "Writing TFRecord 12 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  825.5  (sec)\n",
      "\n",
      "Writing TFRecord 13 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  825.3  (sec)\n",
      "\n",
      "Writing TFRecord 14 of 18...\n",
      "# # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  835.9  (sec)\n",
      "\n",
      "Writing TFRecord 15 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  824.6  (sec)\n",
      "\n",
      "Writing TFRecord 16 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  814.7  (sec)\n",
      "\n",
      "Writing TFRecord 17 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  816.1  (sec)\n",
      "\n",
      "Writing TFRecord 18 of 18...\n",
      "# # # # # # # # # # # # \n",
      "Elapsed:  463.7  (sec)\n"
     ]
    }
   ],
   "source": [
    "# how many imgs in file\n",
    "SIZE = 2000\n",
    "\n",
    "IMG_PIXEL = 512\n",
    "\n",
    "# dataframe where to take metadata\n",
    "df = df_labels \n",
    "\n",
    "# imgs to process\n",
    "IMGS = df['image'].values\n",
    "\n",
    "CT = len(IMGS)//SIZE + int(len(IMGS)%SIZE!=0)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(CT):\n",
    "    print(); \n",
    "    print('Writing TFRecord %i of %i...'%(j+1, CT))\n",
    "    \n",
    "    tStart = time.time()\n",
    "    \n",
    "    CT2 = min(SIZE, len(IMGS)-j*SIZE)\n",
    "    \n",
    "    with tf.io.TFRecordWriter(os.path.join(TFREC_DIR, 'train%.2i-%i.tfrec'%(j,CT2))) as writer:\n",
    "        for k in range(CT2):\n",
    "            index = SIZE*j+k\n",
    "            img_path = os.path.join(TRAIN_IMAGES_DIR, df.iloc[index].image) + '.jpeg'\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # per default CV2 legge in BGR\n",
    "        \n",
    "            # img = cv2.resize(img, (IMG_PIXEL, IMG_PIXEL), interpolation = cv2.INTER_AREA)\n",
    "            img = preprocess_image(img, crop=True, blur = True, sigmaX=10)\n",
    "            \n",
    "            # potrei cambiare la qualità !!! portarla al 100%\n",
    "            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tobytes()\n",
    "            \n",
    "            name = IMGS[index]\n",
    "            \n",
    "            # get the row from Dataframe\n",
    "            row = df.iloc[index]\n",
    "            \n",
    "            # get patientId\n",
    "            patientID = int(row['image'].split('_')[0])\n",
    "            \n",
    "            # encode side: left = 0, right = 1\n",
    "            if 'left' in row['image']:\n",
    "                side = 0\n",
    "            else:\n",
    "                side = 1\n",
    "            \n",
    "            level = row['level']\n",
    "            \n",
    "            # build the record\n",
    "            # image, patientid, side, label\n",
    "            example = serialize_example(img, patientID, side, level)\n",
    "                \n",
    "            writer.write(example)\n",
    "            \n",
    "            # print progress\n",
    "            if k%100==0: print('#','',end='')\n",
    "                \n",
    "    tEnd = time.time()\n",
    "    \n",
    "    print('')\n",
    "    print('Elapsed: ', round((tEnd - tStart),1), ' (sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiche sui tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILENAMES = tf.io.gfile.glob(os.path.join(TFREC_DIR,'train*.tfrec'))\n",
    "\n",
    "TRAIN_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contiamo il totale delle immagini (dai nomi)\n",
    "count_data_items(TRAIN_FILENAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imSize = 256\n",
    "IMAGE_SIZE= [256,256]\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    # porto a 256x256\n",
    "    # image = tf.image.resize(image, [imSize,imSize])\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        'patient_id' : tf.io.FixedLenFeature([], tf.int64), \n",
    "        'side' : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label' : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    \n",
    "    image = decode_image(example['image'])\n",
    "    patient_id = example['patient_id']\n",
    "    side = example['side']\n",
    "    label = example['label']\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(filenames):\n",
    "    dataset = load_dataset(filenames, labeled=True)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = get_training_dataset(TRAIN_FILENAMES)\n",
    "train_dataset = train_dataset.unbatch().batch(20)\n",
    "train_batch = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test: reading TFREcords file...')\n",
    "print(\"Examples of the train data:\")\n",
    "\n",
    "print()\n",
    "\n",
    "batch_num = 0\n",
    "\n",
    "for image, label in train_dataset.take(5):\n",
    "    batch_num += 1\n",
    "    print('')\n",
    "    print('Batch num. ', batch_num)\n",
    "    print(\"The image batch size:\", image.numpy().shape)\n",
    "    print(\"Label\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, seems OK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
